/*
 * -------------------------------------------------
 *  shotgunmetagenomics-nf Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */


// Configurable variables/defaults
params {
    // defaults. best not changed
    pipelineVersion     = '0.0.1dev' // Pipeline version
    read_path           = false
    reads               = false
    decont_off          = false
    profilers           = 'metaphlan2,kraken2,humann2,srst2'
    outdir              = './pipeline_output'
    tracedir            = "${params.outdir}"
    awsregion           = false
    awsqueue            = false
    conda_init          = '~/miniconda3/etc/profile.d/conda.sh'
}


profiles {
    standard {
      includeConfig 'conf/base.config'
    }
    //conda { process.conda = "$baseDir/environment.yml" }
    // TODO: I prefer to use multiple conda envrionments for different small tasks.
    docker { docker.enabled = true }
    singularity {
      singularity.enabled = true
      singularity.autoMounts = true
    }
    conda {
      includeConfig 'conf/base.config'
      includeConfig 'conf/conda.config'
    }
    awsbatch {
      includeConfig 'conf/base.config'
      includeConfig 'conf/awsbatch.config'
    }
    gis {
      includeConfig 'conf/base.config'
      includeConfig 'conf/gis.config'
      includeConfig 'conf/conda.config'
    }
    nscc {
      includeConfig 'conf/base.config'
      includeConfig 'conf/nscc.config'
      includeConfig 'conf/conda.config'
    }
    test {
      includeConfig 'conf/base.config'
      includeConfig 'conf/test.config'
    }
    none {
      // Don't load any config (for use with custom home configs)
    }
}


// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/pipeline_info/shotgunmetagenomics-nf_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/pipeline_info/shotgunmetagenomics-nf_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/pipeline_info/shotgunmetagenomics-nf_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_info/shotgunmetagenomics-nf_DAG.svg"
}


manifest {
  name = 'nf-core/shotgunmetagenomics'
  description = 'Reference-based shotgun metagenomics analysis pipeline, part of the nf-core community.'
  homePage = 'https://github.com/nf-core/shotgunmetagenomics-nf'
  author = 'Chenhao Li'
  // TODO: Define only here if/when we can. See https://github.com/nextflow-io/nextflow/issues/840
  version = params.pipelineVersion
  mainScript = 'main.nf'
  nextflowVersion = '>=19.09.0-edge'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
